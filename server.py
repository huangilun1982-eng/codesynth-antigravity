# server.py - å°ˆæ¡ˆæ§åˆ¶å°å¾Œç«¯
from fastapi import FastAPI
from pydantic import BaseModel
import uvicorn
import sqlite3
import os
import sys
import time
from datetime import datetime
import json
import subprocess
from pathlib import Path
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional
import logging

# Schema ç‰ˆæœ¬æ§åˆ¶
DB_VERSION = 2  # ç•¶å‰è³‡æ–™åº« Schema ç‰ˆæœ¬

# æˆªåœ–åŠŸèƒ½
try:
    import mss
    import mss.tools
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("[WARNING] mss æœªå®‰è£ï¼Œæˆªåœ–åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨ã€‚è«‹åŸ·è¡Œï¼špip install mss")

# CodeSynth å°ˆæ³¨æ–¼ç‰ˆæœ¬ç®¡ç†
# AI åŠŸèƒ½è«‹ä½¿ç”¨ Antigravity å°è©±

app = FastAPI()

class SnapshotRequest(BaseModel):
    project_path: str
    file_path: str
    content: str
    trigger: str

# ==========================================
# å®‰å…¨æ€§ï¼šè¼¸å…¥é©—è­‰
# ==========================================

def validate_project_path(path: str) -> str:
    """
    é©—è­‰å°ˆæ¡ˆè·¯å¾‘çš„å®‰å…¨æ€§
    é˜²æ­¢è·¯å¾‘éæ­·å’Œè¨ªå•æ•æ„Ÿç›®éŒ„
    """
    # 1. è½‰æ›ç‚ºçµ•å°è·¯å¾‘
    abs_path = os.path.abspath(path)
    
    # 2. æª¢æŸ¥è·¯å¾‘æ˜¯å¦å­˜åœ¨
    if not os.path.exists(abs_path):
        raise ValueError(f"è·¯å¾‘ä¸å­˜åœ¨: {abs_path}")
    
    # 3. æª¢æŸ¥æ˜¯å¦ç‚ºç›®éŒ„
    if not os.path.isdir(abs_path):
        raise ValueError(f"ä¸æ˜¯ç›®éŒ„: {abs_path}")
    
    # 4. æª¢æŸ¥å¯«å…¥æ¬Šé™
    if not os.access(abs_path, os.W_OK):
        raise ValueError(f"ç„¡å¯«å…¥æ¬Šé™: {abs_path}")
    
    # 5. ç¦æ­¢ç³»çµ±ç›®éŒ„ï¼ˆWindows å’Œ Linuxï¼‰
    forbidden_patterns = [
        "C:\\Windows", "C:\\Program Files",  # Windows
        "/root", "/etc", "/sys", "/proc", "/boot"  # Linux
    ]
    
    for forbidden in forbidden_patterns:
        if abs_path.startswith(forbidden):
            raise ValueError(f"ç¦æ­¢è¨ªå•ç³»çµ±ç›®éŒ„: {abs_path}")
    
    return abs_path

def validate_file_path(file_path: str) -> str:
    """
    é©—è­‰æª”æ¡ˆè·¯å¾‘çš„å®‰å…¨æ€§
    é˜²æ­¢è·¯å¾‘éæ­·æ”»æ“Š
    """
    # ç¦æ­¢è·¯å¾‘éæ­·
    if '..' in file_path:
        raise ValueError("éæ³•æª”æ¡ˆè·¯å¾‘ï¼šåŒ…å« '..'")
    
    # ç¦æ­¢çµ•å°è·¯å¾‘
    if os.path.isabs(file_path):
        raise ValueError("éæ³•æª”æ¡ˆè·¯å¾‘ï¼šä¸å…è¨±çµ•å°è·¯å¾‘")
    
    return file_path

def get_db(project_path):
    db_path = os.path.join(project_path, "codesynth_history.db")
    conn = sqlite3.connect(db_path)
    # ç¢ºä¿è³‡æ–™è¡¨å­˜åœ¨
    # å»ºç«‹ç°¡å–®çš„æ­·å²è¡¨ï¼šå“ªå€‹æª”æ¡ˆã€ä»€éº¼æ™‚å€™ã€å…§å®¹æ˜¯ä»€éº¼
    c = conn.cursor()
    
    # [Mod] Phase 5: Add status column
    # Check if 'status' column exists in history
    try:
        c.execute("SELECT status FROM history LIMIT 1")
    except sqlite3.OperationalError:
        # Column missing, add it
        try:
            c.execute("ALTER TABLE history ADD COLUMN status TEXT DEFAULT 'pending'")
            print("[INFO] DB Schema Updated: Added 'status' column.")
        except: pass

    # [Mod] Feature Tag System: Add feature_tag column
    try:
        c.execute("SELECT feature_tag FROM history LIMIT 1")
    except sqlite3.OperationalError:
        # Column missing, add it
        try:
            c.execute("ALTER TABLE history ADD COLUMN feature_tag TEXT")
            print("[INFO] DB Schema Updated: Added 'feature_tag' column.")
        except: pass

    c.execute('''CREATE TABLE IF NOT EXISTS history
                 (id INTEGER PRIMARY KEY AUTOINCREMENT, 
                  file_path TEXT, 
                  content TEXT, 
                  timestamp REAL,
                  trigger TEXT,
                  status TEXT DEFAULT 'pending',
                  feature_tag TEXT)''') # åŠŸèƒ½æ¨™ç±¤
                  
    # è¡¨ 2: components (Blueprint Mode - èˆŠç‰ˆç›¸å®¹)
    # ç”¨æ–¼ç¶­æŒã€Œçµ„ä»¶åŒ–ã€çš„è¦–åœ–
    c.execute('''CREATE TABLE IF NOT EXISTS components
                 (id INTEGER PRIMARY KEY AUTOINCREMENT, 
                  component_name TEXT UNIQUE,
                  active INTEGER DEFAULT 1)''')
    
    # è¡¨ 3: screenshots (æ¸¬è©¦å¤±æ•—è‡ªå‹•æˆªåœ–)
    c.execute('''CREATE TABLE IF NOT EXISTS screenshots
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  version_id INTEGER,
                  file_path TEXT,
                  screenshot_path TEXT,
                  error_message TEXT,
                  timestamp REAL,
                  test_status TEXT,
                  FOREIGN KEY (version_id) REFERENCES history(id))''')
    
    # è¡¨ 4: ai_friendly_log (AI å‹å¥½çš„æ­·ç¨‹è¨˜éŒ„)
    c.execute('''CREATE TABLE IF NOT EXISTS ai_friendly_log
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  session_id TEXT,
                  timestamp REAL,
                  what_happened TEXT,
                  current_status TEXT,
                  related_files TEXT,
                  related_versions TEXT,
                  test_result TEXT,
                  error_message TEXT,
                  screenshot_path TEXT,
                  ai_summary TEXT,
                  next_action TEXT)''')
    
    conn.commit()
    return conn, db_path

# ==========================================
# AI å‹å¥½æ­·ç¨‹è¨˜éŒ„å‡½æ•¸
# ==========================================

import uuid
import json

def get_session_id():
    """ç²å–æˆ–ç”Ÿæˆç•¶å‰å·¥ä½œéšæ®µ ID"""
    # ç°¡å–®å¯¦ä½œï¼šä½¿ç”¨ç•¶å¤©æ—¥æœŸä½œç‚º session_id
    from datetime import datetime
    return datetime.now().strftime("%Y%m%d")

def log_ai_event(project_path, what_happened, current_status, **kwargs):
    """è‡ªå‹•è¨˜éŒ„äº‹ä»¶åˆ° AI å‹å¥½æ—¥èªŒ"""
    try:
        conn, _ = get_db(project_path)
        c = conn.cursor()
        
        session_id = get_session_id()
        timestamp = time.time()
        
        # æå–å¯é¸åƒæ•¸
        related_files = json.dumps(kwargs.get('related_files', []))
        related_versions = json.dumps(kwargs.get('related_versions', []))
        test_result = kwargs.get('test_result')
        error_message = kwargs.get('error_message')
        screenshot_path = kwargs.get('screenshot_path')
        ai_summary = kwargs.get('ai_summary')
        next_action = kwargs.get('next_action')
        
        c.execute("""INSERT INTO ai_friendly_log 
                     (session_id, timestamp, what_happened, current_status,
                      related_files, related_versions, test_result, error_message,
                      screenshot_path, ai_summary, next_action)
                     VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                  (session_id, timestamp, what_happened, current_status,
                   related_files, related_versions, test_result, error_message,
                   screenshot_path, ai_summary, next_action))
        
        conn.commit()
        conn.close()
        print(f"ğŸ“ AI Log: {what_happened}")
    except Exception as e:
        print(f"âš ï¸ AI Log è¨˜éŒ„å¤±æ•—: {e}")

@app.post("/api/simulation/start")
async def start_simulation(data: dict):
    """
    åŸ·è¡Œæ¸¬è©¦æ¨¡æ“¬ï¼š
    1. å¾è³‡æ–™åº«æå–é¸å®šç‰ˆæœ¬çš„ç¨‹å¼ç¢¼
    2. å»ºç«‹è‡¨æ™‚åŸ·è¡Œç’°å¢ƒ _sim_temp
    3. åŸ·è¡Œ main.py
    4. è¿”å›åŸ·è¡Œçµæœ
    """
    import subprocess
    import shutil
    
    project_path = data.get('project_path')
    selection = data.get('selection', {})  # {file_path: version_id}
    
    print(f"ğŸš€ Simulation Requested for Project: {project_path}")
    print(f"   Selection: {selection}")
    
    if not project_path:
        return {"status": "error", "message": "æœªæä¾›å°ˆæ¡ˆè·¯å¾‘", "output": ""}
    
    # 1. å»ºç«‹è‡¨æ™‚åŸ·è¡Œç›®éŒ„
    sim_dir = os.path.join(project_path, "_sim_temp")
    if os.path.exists(sim_dir):
        try:
            shutil.rmtree(sim_dir)
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†èˆŠç›®éŒ„å¤±æ•—: {e}")
    
    try:
        os.makedirs(sim_dir)
    except Exception as e:
        return {"status": "error", "message": f"å»ºç«‹åŸ·è¡Œç›®éŒ„å¤±æ•—: {e}", "output": ""}
    
    # 2. å¾è³‡æ–™åº«æå–ç¨‹å¼ç¢¼ä¸¦å¯«å…¥æª”æ¡ˆ
    conn, _ = get_db(project_path)
    c = conn.cursor()
    
    main_file = None
    files_written = []
    
    for file_path, version_id in selection.items():
        # å¾ history è¡¨å–å¾—ç¨‹å¼ç¢¼
        c.execute("SELECT content FROM history WHERE id=?", (version_id,))
        row = c.fetchone()
        
        if not row:
            conn.close()
            return {"status": "error", "message": f"æ‰¾ä¸åˆ°ç‰ˆæœ¬ ID: {version_id}", "output": ""}
        
        code = row[0]
        
        # æ±ºå®šæª”æ¡ˆåç¨±
        file_name = os.path.basename(file_path)
        # ç¢ºä¿å­ç›®éŒ„çµæ§‹è¢«ä¿ç•™
        relative_path = os.path.relpath(file_path, project_path)
        target_file_path = os.path.join(sim_dir, relative_path)
        os.makedirs(os.path.dirname(target_file_path), exist_ok=True)

        # æª¢æŸ¥æ˜¯å¦ç‚ºä¸»ç¨‹å¼
        if 'main.py' in file_name.lower(): # æ‡‰è©²æ˜¯æª¢æŸ¥å®Œæ•´çš„ç›¸å°è·¯å¾‘
            main_file = target_file_path
        
        # å¯«å…¥æª”æ¡ˆ
        try:
            with open(target_file_path, 'w', encoding='utf-8') as f:
                f.write(code)
            files_written.append(relative_path)
            print(f"   âœ… å¯«å…¥: {relative_path}")
        except Exception as e:
            conn.close()
            return {"status": "error", "message": f"å¯«å…¥æª”æ¡ˆå¤±æ•—: {e}", "output": ""}
    
    conn.close()
    
    # 3. æª¢æŸ¥æ˜¯å¦æœ‰ main.py
    if not main_file:
        # å˜—è©¦å¾ selection ä¸­æ‰¾åˆ°ä¸€å€‹ä½œç‚º main_file
        for fp, vid in selection.items():
            if 'main.py' in fp.lower():
                main_file = os.path.join(sim_dir, os.path.relpath(fp, project_path))
                break
        if not main_file:
            return {"status": "error", "message": "æœªé¸æ“‡ main.pyï¼Œç„¡æ³•åŸ·è¡Œ", "output": "", "files": files_written}
    
    # 4. åŸ·è¡Œç¨‹å¼
    print(f"   ğŸ”¥ åŸ·è¡Œ: {os.path.basename(main_file)}")
    
    # å–å¾— main.py çš„ version_idï¼Œç”¨æ–¼æˆªåœ–
    main_file_rel_path = os.path.relpath(main_file, sim_dir)
    main_version_id = selection.get(main_file_rel_path)
    if not main_version_id:
        # å¦‚æœ main_file_rel_path ä¸åœ¨ selection è£¡ (ä¾‹å¦‚æ˜¯ project_path/main.py)
        # å‰‡å˜—è©¦å¾ selection ä¸­æ‰¾åˆ°ç¬¬ä¸€å€‹ main.py çš„ version_id
        for fp, vid in selection.items():
            if 'main.py' in fp.lower():
                main_version_id = vid
                break
        if not main_version_id and selection: # å¦‚æœé‚„æ˜¯æ²’æœ‰ï¼Œå°±ç”¨ç¬¬ä¸€å€‹æª”æ¡ˆçš„ version_id ä½œç‚ºä»£è¡¨
            main_version_id = list(selection.values())[0]

    try:
        process = subprocess.Popen(
            [sys.executable, main_file],
            cwd=sim_dir,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=False # Changed to False to handle decoding manually
        )
        
        stdout_output, stderr_output = process.communicate(timeout=30)
        stdout = stdout_output.decode('utf-8', errors='ignore')
        stderr = stderr_output.decode('utf-8', errors='ignore')
        
        if process.returncode == 0:
            return {
                "status": "success",
                "message": "åŸ·è¡ŒæˆåŠŸ",
                "output": stdout,
                "error": stderr if stderr else "",
                "exit_code": 0,
                "files": files_written
            }
        else:
            error_msg = f"åŸ·è¡Œå¤±æ•— (Exit Code: {process.returncode})"
            
            # â­ æ¸¬è©¦å¤±æ•—æ™‚è‡ªå‹•æˆªåœ–
            screenshot_path = take_screenshot(
                project_path,
                version_id=main_version_id,
                file_path='main.py',
                error_msg=stderr or stdout or error_msg,
                status='failed'
            )
            
            # AI å‹å¥½è¨˜éŒ„ï¼šæ¸¬è©¦å¤±æ•—
            log_ai_event(
                project_path,
                what_happened="ç”¨æˆ¶åŸ·è¡Œæ¸¬è©¦å¤±æ•—",
                current_status="é‡åˆ°å•é¡Œéœ€è¦ä¿®æ­£",
                test_result="å¤±æ•—",
                error_message=stderr or stdout or error_msg,
                screenshot_path=screenshot_path,
                ai_summary=f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—ï¼š{error_msg}ã€‚å·²è‡ªå‹•æˆªåœ–ä¿å­˜å•é¡Œç•«é¢ã€‚",
                next_action="å»ºè­°æŸ¥çœ‹éŒ¯èª¤è¨Šæ¯æˆ–æˆªåœ–ï¼Œä¿®æ­£ä»£ç¢¼å¾Œé‡æ–°æ¸¬è©¦"
            )
            
            return {
                "status": "failed",
                "message": error_msg,
                "output": stdout,
                "error": stderr,
                "exit_code": process.returncode,
                "files": files_written,
                "screenshot": screenshot_path  # è¿”å›æˆªåœ–è·¯å¾‘
            }
    
    except subprocess.TimeoutExpired:
        process.kill()
        error_msg = "åŸ·è¡Œé€¾æ™‚ (è¶…é 30 ç§’)"
        
        # â­ è¶…æ™‚ä¹Ÿæˆªåœ–
        screenshot_path = take_screenshot(
            project_path,
            version_id=main_version_id,
            file_path='main.py',
            error_msg=error_msg,
            status='timeout'
        )
        
        return {
            "status": "timeout",
            "message": error_msg,
            "output": "",
            "error": "Process killed due to timeout",
            "files": files_written,
            "screenshot": screenshot_path
        }
    except Exception as e:
        error_msg = f"åŸ·è¡Œéç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
        
        # â­ éŒ¯èª¤ä¹Ÿæˆªåœ–
        screenshot_path = take_screenshot(
            project_path,
            version_id=main_version_id if main_version_id else 0,
            file_path='main.py',
            error_msg=error_msg,
            status='error'
        )
        
        return {
            "status": "error",
            "message": error_msg,
            "output": "",
            "error": str(e),
            "files": files_written,
            "screenshot": screenshot_path
        }

@app.post("/api/snapshot")
async def save_snapshot(req: SnapshotRequest):
    """ä¿å­˜å–®ä¸€æª”æ¡ˆå¿«ç…§ - å¸¶å®Œæ•´éŒ¯èª¤è™•ç†"""
    conn = None
    try:
        print(f"[DEBUG] æ”¶åˆ°å¿«ç…§è«‹æ±‚: {req.file_path}")
        
        # 1. é©—è­‰å°ˆæ¡ˆè·¯å¾‘
        try:
            project_path = validate_project_path(req.project_path)
            print(f"[DEBUG] å°ˆæ¡ˆè·¯å¾‘é©—è­‰é€šé: {project_path}")
        except ValueError as e:
            print(f"[ERROR] å°ˆæ¡ˆè·¯å¾‘é©—è­‰å¤±æ•—: {e}")
            return {"status": "error", "message": f"å°ˆæ¡ˆè·¯å¾‘ç„¡æ•ˆ: {str(e)}"}
        except Exception as e:
            print(f"[ERROR] å°ˆæ¡ˆè·¯å¾‘é©—è­‰ç•°å¸¸: {type(e).__name__}: {e}")
            return {"status": "error", "message": f"è·¯å¾‘é©—è­‰éŒ¯èª¤: {str(e)}"}
        
        # 2. é©—è­‰æª”æ¡ˆè·¯å¾‘
        try:
            file_path = validate_file_path(req.file_path)
            print(f"[DEBUG] æª”æ¡ˆè·¯å¾‘é©—è­‰é€šé: {file_path}")
        except ValueError as e:
            print(f"[ERROR] æª”æ¡ˆè·¯å¾‘é©—è­‰å¤±æ•—: {e}")
            return {"status": "error", "message": f"æª”æ¡ˆè·¯å¾‘ç„¡æ•ˆ: {str(e)}"}
        except Exception as e:
            print(f"[ERROR] æª”æ¡ˆè·¯å¾‘é©—è­‰ç•°å¸¸: {type(e).__name__}: {e}")
            return {"status": "error", "message": f"è·¯å¾‘é©—è­‰éŒ¯èª¤: {str(e)}"}
        
        # 3. æª”æ¡ˆå¤§å°æª¢æŸ¥
        content_size = len(req.content)
        MAX_SIZE = 10 * 1024 * 1024  # 10MB
        if content_size > MAX_SIZE:
            error_msg = f"æª”æ¡ˆéå¤§ ({content_size/1024/1024:.1f}MB)ï¼Œé™åˆ¶ 10MB"
            print(f"[ERROR] {error_msg}")
            return {"status": "error", "message": error_msg}
        
        # 4. å–å¾—è³‡æ–™åº«é€£æ¥
        try:
            conn, _ = get_db(project_path)
            c = conn.cursor()
            print(f"[DEBUG] è³‡æ–™åº«é€£æ¥æˆåŠŸ")
        except Exception as e:
            print(f"[ERROR] è³‡æ–™åº«é€£æ¥å¤±æ•—: {type(e).__name__}: {e}")
            return {"status": "error", "message": f"è³‡æ–™åº«é€£æ¥å¤±æ•—: {str(e)}"}
        
        # 5. æ’å…¥è³‡æ–™åº«ï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰
        version_id = None
        for attempt in range(5):
            try:
                c.execute("""INSERT INTO history 
                            (file_path, content, timestamp, trigger, status)
                            VALUES (?, ?, ?, ?, 'pending')""",
                         (file_path, req.content, time.time(), req.trigger))
                conn.commit()
                version_id = c.lastrowid
                print(f"[OK] å·²ä¿å­˜å¿«ç…§: {file_path} (version_id: {version_id})")
                break
            except sqlite3.OperationalError as e:
                if attempt < 4 and "locked" in str(e).lower():
                    print(f"[WARNING] è³‡æ–™åº«é–å®šï¼Œé‡è©¦ {attempt + 1}/5")
                    time.sleep(0.1)
                else:
                    print(f"[ERROR] è³‡æ–™åº«æ“ä½œå¤±æ•—: {e}")
                    raise
            except Exception as e:
                print(f"[ERROR] æ’å…¥è³‡æ–™åº«å¤±æ•—: {type(e).__name__}: {e}")
                raise
        
        # 6. è¨˜éŒ„ AI äº‹ä»¶ï¼ˆéé—œéµï¼Œå¤±æ•—ä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰
        try:
            log_ai_event(
                project_path,
                what_happened=f"ç”¨æˆ¶ä¿®æ”¹äº† {file_path}",
                current_status="ç­‰å¾…æ¸¬è©¦",
                related_files=file_path
            )
        except Exception as e:
            print(f"[WARNING] AI äº‹ä»¶è¨˜éŒ„å¤±æ•—ï¼ˆä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰: {e}")
        
        return {"status": "ok", "version_id": version_id}
        
    except Exception as e:
        # æ•ç²æ‰€æœ‰æœªé æœŸçš„ç•°å¸¸
        error_type = type(e).__name__
        error_msg = str(e)
        print(f"[ERROR] save_snapshot æœªé æœŸéŒ¯èª¤: {error_type}: {error_msg}")
        
        # æ‰“å°å®Œæ•´å †ç–Šä»¥ä¾¿èª¿è©¦
        import traceback
        traceback.print_exc()
        
        # å˜—è©¦å›æ»¾äº‹å‹™
        if conn:
            try:
                conn.rollback()
                print(f"[DEBUG] äº‹å‹™å·²å›æ»¾")
            except Exception as rollback_error:
                print(f"[WARNING] å›æ»¾å¤±æ•—: {rollback_error}")
        
        return {"status": "error", "message": f"ä¿å­˜å¤±æ•—: {error_type}: {error_msg}"}
        
    finally:
        # ç¢ºä¿é—œé–‰é€£æ¥
        if conn:
            try:
                conn.close()
                print(f"[DEBUG] è³‡æ–™åº«é€£æ¥å·²é—œé–‰")
            except Exception as close_error:
                print(f"[WARNING] é—œé–‰é€£æ¥å¤±æ•—: {close_error}")


@app.post("/api/update_status")
async def update_status(data: dict):
    """
    æ›´æ–°ç‰¹å®šç‰ˆæœ¬çš„ç‹€æ…‹ (Success/Failed)
    """
    project_path = data.get('project_path')
    ver_id = data.get('id')
    status = data.get('status') # 'success' or 'failed' or 'pending'
    
    conn, _ = get_db(project_path)
    c = conn.cursor()
    c.execute("UPDATE history SET status=? WHERE id=?", (status, ver_id))
    conn.commit()
    conn.close()
    return {"status": "updated"}

@app.post("/api/batch_snapshot")
async def batch_snapshot(data: dict):
    """æ‰¹æ¬¡ä¿å­˜å¤šå€‹æª”æ¡ˆå¿«ç…§"""
    conn = None
    try:
        project_path = validate_project_path(data['project_path'])
        snapshots = data.get('snapshots', [])
        
        if not snapshots:
            return {"status": "error", "message": "æ²’æœ‰è¦ä¿å­˜çš„å¿«ç…§"}
        
        conn, _ = get_db(project_path)
        c = conn.cursor()
        
        success_count = 0
        errors = []
        MAX_SIZE = 10 * 1024 * 1024  # 10MB
        
        for snapshot in snapshots:
            try:
                file_path = validate_file_path(snapshot['file_path'])
                content = snapshot['content']
                trigger = snapshot.get('trigger', 'Batch Scan')
                
                # æª”æ¡ˆå¤§å°æª¢æŸ¥
                if len(content) > MAX_SIZE:
                    errors.append({
                        'file': file_path,
                        'error': f'æª”æ¡ˆéå¤§ ({len(content)/1024/1024:.1f}MB)ï¼Œé™åˆ¶ 10MB'
                    })
                    continue
                
                # æ’å…¥è³‡æ–™åº«
                c.execute("""INSERT INTO history 
                            (file_path, content, timestamp, trigger, status)
                            VALUES (?, ?, ?, ?, 'pending')""",
                         (file_path, content, time.time(), trigger))
                
                success_count += 1
                
            except ValueError as e:
                errors.append({
                    'file': snapshot.get('file_path', 'unknown'),
                    'error': str(e)
                })
            except Exception as e:
                errors.append({
                    'file': snapshot.get('file_path', 'unknown'),
                    'error': f'å„²å­˜å¤±æ•—: {str(e)}'
                })
        
        conn.commit()
        
        return {
            'status': 'ok',
            'success_count': success_count,
            'total': len(snapshots),
            'errors': errors
        }
        
    except ValueError as e:
        return {"status": "error", "message": str(e)}
    except Exception as e:
        print(f"[ERROR] æ‰¹æ¬¡å¿«ç…§å¤±æ•—: {e}")
        if conn:
            conn.rollback()
        return {"status": "error", "message": "æ‰¹æ¬¡ä¿å­˜å¤±æ•—"}
    finally:
        if conn:
            conn.close()

@app.post("/api/dashboard")
async def get_dashboard_data(data: dict):
    """
    æ ¸å¿ƒåŠŸèƒ½ï¼šå›å‚³ã€Œè—åœ–ã€è³‡æ–™
    æ ¼å¼ï¼š{ "main.py": [v1, v2...], "utils.py": [v1, v2...] }
    """
    project_path = data.get('project_path')
    if not os.path.exists(os.path.join(project_path, "codesynth_history.db")):
        return {"files": {}}

    conn, _ = get_db(project_path)
    c = conn.cursor()
    
    # 1. æ‰¾å‡ºæ‰€æœ‰æª”æ¡ˆ
    c.execute("SELECT DISTINCT file_path FROM history ORDER BY file_path")
    files = [r[0] for r in c.fetchall()]
    
    dashboard = {}
    for f in files:
        # [Mod] Fix UI Clutter: Ignore external files or .gemini folder
        if f.startswith("..") or ".gemini" in f or os.path.isabs(f):
            continue

        # 2. æ‰¾å‡ºæ¯å€‹æª”æ¡ˆçš„æ‰€æœ‰ç‰ˆæœ¬ (åªå– ID, æ™‚é–“, è§¸ç™¼åŸå› , status, feature_tag)
        c.execute("SELECT id, timestamp, trigger, status, feature_tag FROM history WHERE file_path=? ORDER BY id DESC", (f,))
        versions = []
        for r in c.fetchall():
            ts = time.strftime('%m-%d %H:%M', time.localtime(r[1]))
            st = r[3] if r[3] else 'pending'
            ft = r[4] if r[4] else None  # feature_tag
            versions.append({
                "id": r[0], 
                "label": f"[{ts}] {r[2]}", 
                "full_time": ts, 
                "status": st,
                "feature_tag": ft
            })
        dashboard[f] = versions
        
    conn.close()
    return {"files": dashboard}

@app.post("/api/get_version_content")
async def get_version_content(data: dict):
    """å–å¾—ç‰¹å®šç‰ˆæœ¬çš„ç¨‹å¼ç¢¼å…§å®¹"""
    conn, _ = get_db(data['project_path'])
    c = conn.cursor()
    c.execute("SELECT content FROM history WHERE id=?", (data['id'],))
    row = c.fetchone()
    conn.close()
    return {"content": row[0] if row else ""}

# ==========================================
# åŠŸèƒ½æ¨™ç±¤ API ç«¯é»
# ==========================================

@app.post("/api/update_tag")
async def update_tag(data: dict):
    """æ›´æ–°å–®ä¸€ç‰ˆæœ¬çš„åŠŸèƒ½æ¨™ç±¤"""
    project_path = data.get('project_path')
    version_id = data.get('version_id')
    feature_tag = data.get('feature_tag')
    
    conn, _ = get_db(project_path)
    c = conn.cursor()
    c.execute("UPDATE history SET feature_tag=? WHERE id=?", 
              (feature_tag, version_id))
    conn.commit()
    conn.close()
    
    return {"status": "success", "message": f"å·²æ›´æ–°ç‰ˆæœ¬ {version_id} çš„æ¨™ç±¤"}

@app.post("/api/batch_update_tags")
async def batch_update_tags(data: dict):
    """æ‰¹æ¬¡æ›´æ–°å¤šå€‹ç‰ˆæœ¬çš„åŠŸèƒ½æ¨™ç±¤"""
    project_path = data.get('project_path')
    version_ids = data.get('version_ids')  # list of version IDs
    feature_tag = data.get('feature_tag')
    
    conn, _ = get_db(project_path)
    c = conn.cursor()
    
    for version_id in version_ids:
        c.execute("UPDATE history SET feature_tag=? WHERE id=?", 
                  (feature_tag, version_id))
    
    conn.commit()
    conn.close()
    
    return {
        "status": "success", 
        "message": f"å·²ç‚º {len(version_ids)} å€‹ç‰ˆæœ¬æ›´æ–°æ¨™ç±¤",
        "count": len(version_ids)
    }

@app.post("/api/get_tags")
async def get_tags(data: dict):
    """å–å¾—å°ˆæ¡ˆä¸­æ‰€æœ‰åŠŸèƒ½æ¨™ç±¤æ¸…å–®"""
    project_path = data.get('project_path')
    
    conn, _ = get_db(project_path)
    c = conn.cursor()
    c.execute("SELECT DISTINCT feature_tag FROM history WHERE feature_tag IS NOT NULL ORDER BY feature_tag")
    tags = [row[0] for row in c.fetchall()]
    conn.close()
    
    return {"tags": tags}

@app.post("/api/get_versions_by_tag")
async def get_versions_by_tag(data: dict):
    """ä¾åŠŸèƒ½æ¨™ç±¤å–å¾—ç›¸é—œç‰ˆæœ¬"""
    project_path = data.get('project_path')
    feature_tag = data.get('feature_tag')
    
    conn, _ = get_db(project_path)
    c = conn.cursor()
    c.execute("""SELECT id, file_path, timestamp, trigger, status 
                 FROM history 
                 WHERE feature_tag=? 
                 ORDER BY file_path, timestamp DESC""", 
              (feature_tag,))
    
    rows = c.fetchall()
    conn.close()
    
    # çµ„ç¹”ç‚º {file_path: [versions]}
    result = {}
    for row in rows:
        file_path = row[1]
        if file_path not in result:
            result[file_path] = []
        result[file_path].append({
            "id": row[0],
            "timestamp": row[2],
            "trigger": row[3],
            "status": row[4]
        })
    
    return {"versions": result, "tag": feature_tag}

# ==========================================
# æ¸¬è©¦å¤±æ•—è‡ªå‹•æˆªåœ–åŠŸèƒ½
# ==========================================

def take_screenshot(project_path, version_id, file_path, error_msg, status):
    """æ¸¬è©¦å¤±æ•—æ™‚è‡ªå‹•æˆªåœ–"""
    if not MSS_AVAILABLE:
        print("[WARNING] æˆªåœ–åŠŸèƒ½ä¸å¯ç”¨ï¼šmss æœªå®‰è£")
        return None
    
    try:
        # å»ºç«‹æˆªåœ–ç›®éŒ„
        screenshots_dir = os.path.join(project_path, "screenshots")
        os.makedirs(screenshots_dir, exist_ok=True)
        
        # ç”Ÿæˆæª”å
        timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"error_{timestamp_str}_{version_id}.png"
        screenshot_path = os.path.join(screenshots_dir, filename)
        
        # æˆªåœ–
        with mss.mss() as sct:
            # æˆªå–ä¸»è¢å¹•
            screenshot = sct.grab(sct.monitors[1])
            # ä¿å­˜
            mss.tools.to_png(screenshot.rgb, screenshot.size, output=screenshot_path)
        
        # ä¿å­˜åˆ°è³‡æ–™åº«
        conn, _ = get_db(project_path)
        c = conn.cursor()
        c.execute("""INSERT INTO screenshots 
                     (version_id, file_path, screenshot_path, 
                      error_message, timestamp, test_status)
                     VALUES (?, ?, ?, ?, ?, ?)""",
                  (version_id, file_path, screenshot_path, 
                   error_msg, time.time(), status))
        conn.commit()
        conn.close()
        
        print(f"ğŸ“¸ å·²è‡ªå‹•æˆªåœ–: {screenshot_path}")
        return screenshot_path
    except Exception as e:
        print(f"âŒ æˆªåœ–å¤±æ•—: {e}")
        return None

@app.post("/api/screenshots")
async def get_screenshots(data: dict):
    """å–å¾—ç‰ˆæœ¬çš„æ‰€æœ‰æˆªåœ–"""
    version_id = data.get('version_id')
    project_path = data.get('project_path')
    
    conn, _ = get_db(project_path)
    c = conn.cursor()
    c.execute("""SELECT id, screenshot_path, error_message, timestamp, test_status 
                 FROM screenshots 
                 WHERE version_id=? 
                 ORDER BY timestamp DESC""", 
              (version_id,))
    
    screenshots = []
    for row in c.fetchall():
        screenshots.append({
            "id": row[0],
            "path": row[1],
            "error": row[2],
            "timestamp": row[3],
            "status": row[4]
        })
    
    conn.close()
    return {"screenshots": screenshots}

# ==========================================
# AI ä¸Šä¸‹æ–‡æŸ¥è©¢ API
# ==========================================

@app.post("/api/ai/context")
async def get_ai_context(data: dict):
    """
    ç‚º AI æä¾›å®Œæ•´çš„å°ˆæ¡ˆä¸Šä¸‹æ–‡
    è®“ AI å¿«é€Ÿç†è§£å°ˆæ¡ˆé€²åº¦å’Œç‹€æ…‹
    """
    project_path = data.get('project_path')
    limit = data.get('limit', 20)  # æœ€è¿‘Næ¢è¨˜éŒ„
    
    conn, _ = get_db(project_path)
    c = conn.cursor()
    
    # 1. ç²å–æœ€è¿‘çš„æ­·ç¨‹è¨˜éŒ„
    c.execute("""SELECT what_happened, current_status, test_result, 
                        error_message, screenshot_path, ai_summary, 
                        timestamp
                 FROM ai_friendly_log 
                 WHERE session_id = ?
                 ORDER BY timestamp DESC 
                 LIMIT ?""", 
              (get_session_id(), limit))
    
    recent_activities = []
    for row in c.fetchall():
        recent_activities.append({
            "what": row[0],
            "status": row[1],
            "result": row[2],
            "error": row[3],
            "screenshot": row[4],
            "summary": row[5],
            "time": time.strftime('%H:%M', time.localtime(row[6]))
        })
    
    # 2. åˆ†æç•¶å‰ç‹€æ…‹
    c.execute("""SELECT current_status, what_happened 
                 FROM ai_friendly_log 
                 ORDER BY timestamp DESC LIMIT 1""")
    latest = c.fetchone()
    current_task = latest[1] if latest else "å°šæœªé–‹å§‹"
    current_status = latest[0] if latest else "ç­‰å¾…é–‹å§‹"
    
    # 3. æˆåŠŸæ¨¡å¼ï¼ˆæœ€è¿‘æˆåŠŸçš„äº‹ä»¶ï¼‰
    c.execute("""SELECT what_happened, ai_summary 
                 FROM ai_friendly_log 
                 WHERE test_result = 'æˆåŠŸ' 
                 ORDER BY timestamp DESC LIMIT 5""")
    successful_patterns = [{"what": r[0], "summary": r[1]} for r in c.fetchall()]
    
    # 4. å¤±æ•—æ•™è¨“ï¼ˆæœ€è¿‘å¤±æ•—çš„å˜—è©¦ï¼‰
    c.execute("""SELECT what_happened, error_message, screenshot_path 
                 FROM ai_friendly_log 
                 WHERE test_result = 'å¤±æ•—' 
                 ORDER BY timestamp DESC LIMIT 5""")
    failed_attempts = [{
        "what": r[0], 
        "error": r[1], 
        "screenshot": r[2]
    } for r in c.fetchall()]
    
    # 5. ç”Ÿæˆå°ˆæ¡ˆæ‘˜è¦
    c.execute("SELECT COUNT(*) FROM ai_friendly_log")
    total_events = c.fetchone()[0]
    
    c.execute("SELECT COUNT(*) FROM ai_friendly_log WHERE test_result = 'æˆåŠŸ'")
    success_count = c.fetchone()[0]
    
    c.execute("SELECT COUNT(*) FROM ai_friendly_log WHERE test_result = 'å¤±æ•—'")
    failed_count = c.fetchone()[0]
    
    conn.close()
    
    return {
        "summary": f"å°ˆæ¡ˆå·²é€²è¡Œ {total_events} å€‹æ“ä½œï¼ŒæˆåŠŸ {success_count} æ¬¡ï¼Œå¤±æ•— {failed_count} æ¬¡",
        "current_task": current_task,
        "current_status": current_status,
        "recent_activities": recent_activities,
        "successful_patterns": successful_patterns,
        "failed_attempts": failed_attempts,
        "ai_notes": "ç”¨æˆ¶ç‚ºéæŠ€è¡“èƒŒæ™¯ï¼Œå»ºè­°ä½¿ç”¨ç°¡å–®æ˜“æ‡‚çš„èªè¨€"
    }

# ==========================================
# å°ˆæ¡ˆç´¢å¼•ç”Ÿæˆ API
# ==========================================

@app.post("/api/generate_index")
async def generate_project_index(data: dict):
    """
    ç”Ÿæˆå°ˆæ¡ˆç´¢å¼•æª”æ¡ˆ
    è‡ªå‹•æƒæä¸¦è¨˜éŒ„æ‰€æœ‰çµ„ä»¶è³‡è¨Š
    """
    project_path = data.get('project_path')
    
    try:
        # 1. æƒæå°ˆæ¡ˆæª”æ¡ˆ
        files_info = scan_project_files(project_path)
        
        # 2. ç”Ÿæˆç´¢å¼•çµæ§‹
        index = {
            "project_name": os.path.basename(project_path),
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_files": len(files_info),
            "files": files_info,
            "architecture_notes": "ç”± CodeSynth è‡ªå‹•ç”Ÿæˆçš„å°ˆæ¡ˆç´¢å¼•",
            "ai_mode": "hybrid",  # hybrid, ai-driven, human-maintained
            "version": "1.0"
        }
        
        # 3. ä¿å­˜ç´¢å¼•æª”æ¡ˆ
        index_path = os.path.join(project_path, "project_index.json")
        with open(index_path, 'w', encoding='utf-8') as f:
            json.dump(index, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ å·²ç”Ÿæˆå°ˆæ¡ˆç´¢å¼•: {index_path}")
        
        return {
            "status": "success",
            "index_path": index_path,
            "total_files": len(files_info),
            "summary": f"å·²åˆ†æ {len(files_info)} å€‹æª”æ¡ˆ"
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"ç”Ÿæˆç´¢å¼•å¤±æ•—: {str(e)}"
        }

def scan_project_files(project_path):
    """æƒæå°ˆæ¡ˆä¸¦æ”¶é›†æª”æ¡ˆè³‡è¨Š"""
    files_info = {}
    
    # è¦æ’é™¤çš„ç›®éŒ„å’Œæª”æ¡ˆ
    exclude_dirs = {
        'node_modules', '.git', '__pycache__', '.vscode', 
        'temp_simulation', '_sim_temp', 'screenshots',
        '.gemini', 'venv', 'env', 'dist', 'build'
    }
    
    exclude_extensions = {'.pyc', '.pyo', '.db', '.png', '.jpg', '.gif'}
    
    # éæ­·å°ˆæ¡ˆç›®éŒ„
    for root, dirs, files in os.walk(project_path):
        # éæ¿¾æ’é™¤çš„ç›®éŒ„
        dirs[:] = [d for d in dirs if d not in exclude_dirs]
        
        for file in files:
            # éæ¿¾æ’é™¤çš„æª”æ¡ˆ
            if any(file.endswith(ext) for ext in exclude_extensions):
                continue
            
            file_path = os.path.join(root, file)
            relative_path = os.path.relpath(file_path, project_path)
            
            # æ”¶é›†æª”æ¡ˆè³‡è¨Š
            try:
                stat = os.stat(file_path)
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    lines = len(content.splitlines())
                
                files_info[relative_path] = {
                    "size_bytes": stat.st_size,
                    "lines": lines,
                    "last_modified": time.strftime('%Y-%m-%d %H:%M', time.localtime(stat.st_mtime)),
                    "extension": os.path.splitext(file)[1],
                    "purpose": analyze_file_purpose(file, content),
                    "ai_managed": False,  # é è¨­ç‚ºäººé¡ç¶­è­·
                    "dependencies": extract_dependencies(content),
                    "ai_summary": "å¾… AI åˆ†æ"
                }
            except Exception as e:
                print(f"[WARNING] ç„¡æ³•åˆ†æ {relative_path}: {e}")
                continue
    
    return files_info

def analyze_file_purpose(filename, content):
    """ç°¡å–®åˆ†ææª”æ¡ˆç”¨é€”"""
    # æ ¹æ“šæª”ååˆ¤æ–·
    name_lower = filename.lower()
    
    if 'main' in name_lower:
        return "ä¸»ç¨‹å¼å…¥å£"
    elif 'server' in name_lower:
        return "ä¼ºæœå™¨ç¨‹å¼"
    elif 'test' in name_lower:
        return "æ¸¬è©¦ç¨‹å¼"
    elif 'config' in name_lower:
        return "é…ç½®æª”æ¡ˆ"
    elif 'util' in name_lower or 'helper' in name_lower:
        return "å·¥å…·å‡½æ•¸"
    elif 'database' in name_lower or 'db' in name_lower:
        return "è³‡æ–™åº«æ“ä½œ"
    elif filename.endswith('.json'):
        return "JSON é…ç½®æˆ–è³‡æ–™"
    elif filename.endswith('.md'):
        return "æ–‡æª”èªªæ˜"
    else:
        return "ç¨‹å¼é‚è¼¯"

def extract_dependencies(content):
    """æå–æª”æ¡ˆä¾è³´"""
    dependencies = []
    
    # Python import
    import_lines = [line.strip() for line in content.split('\n') 
                   if line.strip().startswith(('import ', 'from '))]
    
    for line in import_lines[:5]:  # åªå–å‰5å€‹
        if 'import ' in line:
            # ç°¡å–®æå–æ¨¡çµ„å
            parts = line.split()
            if len(parts) >= 2:
                module = parts[1].split('.')[0]
                if module not in ['os', 'sys', 'time', 'json']:  # æ’é™¤æ¨™æº–åº«
                    dependencies.append(module)
    
    return dependencies[:5]  # æœ€å¤š5å€‹

@app.post("/api/get_index")
async def get_project_index(data: dict):
    """ç²å–å°ˆæ¡ˆç´¢å¼•"""
    project_path = data.get('project_path')
    index_path = os.path.join(project_path, "project_index.json")
    
    if os.path.exists(index_path):
        with open(index_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        return {"status": "not_found", "message": "ç´¢å¼•æª”æ¡ˆä¸å­˜åœ¨ï¼Œè«‹å…ˆç”Ÿæˆ"}

# ==========================================
# å¥åº·æª¢æŸ¥ API
# ==========================================

@app.get("/health")
async def health_check():
    """
    å¥åº·æª¢æŸ¥ç«¯é»
    ç”¨æ–¼ç¢ºèªä¼ºæœå™¨é‹è¡Œç‹€æ…‹å’ŒåŠŸèƒ½å¯ç”¨æ€§
    """
    health_status = {
        "status": "healthy",
        "version": "1.0.0",
        "schema_version": DB_VERSION,
        "timestamp": datetime.now().isoformat(),
        "features": {
            "version_control": True,
            "test_execution": True,
            "screenshot": MSS_AVAILABLE,
            "ai_history": True,
            "project_index": True,
            "schema_migration": True
        },
        "database": {
            "wal_mode": True,
            "concurrent_support": True
        }
    }
    
    return health_status

@app.get("/")
async def root():
    """æ ¹ç«¯é» - è¿”å›åŸºæœ¬è³‡è¨Š"""
    return {
        "service": "CodeSynth API Server",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "health": "/health",
            "ai_context": "/api/ai/context",
            "generate_index": "/api/generate_index",
            "dashboard": "/api/dashboard"
        }
    }

if __name__ == "__main__":
    print("=" * 50)
    print("CodeSynth æ§åˆ¶å°æœå‹™å•Ÿå‹•ä¸­... (Port: 8000)")
    print("=" * 50)
    if MSS_AVAILABLE:
        print("[OK] æˆªåœ–åŠŸèƒ½å·²å•Ÿç”¨")
    else:
        print("[WARNING] æˆªåœ–åŠŸèƒ½æœªå•Ÿç”¨ï¼ˆmss æœªå®‰è£ï¼‰")
    print("[OK] AI å‹å¥½æ­·ç¨‹è¨˜éŒ„å·²å•Ÿç”¨")
    print("[OK] å°ˆæ¡ˆç´¢å¼•ç”Ÿæˆå·²å•Ÿç”¨")
    print("[OK] Schema ç‰ˆæœ¬ç®¡ç†å·²å•Ÿç”¨")
    print("=" * 50)
    uvicorn.run(app, host="127.0.0.1", port=8000)
